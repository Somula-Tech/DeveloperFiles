
Kubernetes commands

#to setup minicube cluster in local
choco install minikube

minikube image ls

minikube load image user:0.1.Release

minikube start --driver=docker

minikube service user-service(service name)

minikube version

minikube delete

minikube start --driver=docker

minikube status

minikube stop

minikube dashboard

minikube ip


#Kubernetes deployment commands
Port range: 30000â€“32767
A container orchestration system â€” it defines how containers are deployed, scaled, and managed across multiple machines (nodes).

Kubectl get nodes

kubectl apply -f deployment.yaml

kubectl apply -f service.yaml

kubectl get pods

kubectl get svc(services)

kubectl get pods -n kube-system

kubectl exec -it -n kube-system etcd-minikube -- sh



Controller(It will take care of how many pods to be run)
Schedular(It will take care of pods need to run in which node and all)
Kubelet(It will take care of Docker images)

#Automation process of deployment using Kubernetes
creating manifestfile 
And add all the details of deployment.yaml and service.yaml and try to add the command kubectl apply -f deployment/service.yaml

deployment.yaml(#this file will take care of how many pods need to be run and if pod crashes and immediately take the another pod up)
Purpose:	Run & manage Pods 
Description:	Defines the appâ€™s container image, replicas, and update strategy
â€œHow to run my app.â€

service.yaml
Purpose:	Expose Pods 
Description:	Gives stable access to your app over the network
â€œHow to access my app.â€

Service Type		Accessible From				Used In						Typical Use Case
ClusterIP			Inside cluster only			Local, internal services		Backend, DB
NodePort			External (limited)			Local / Minikube					Development, testing
LoadBalancer		Internet (public IP)	Cloud clusters				Production apps

Minikube = Local practice version of Kubernetes
Kubernetes = Real distributed system for production

ğŸŒ Kubernetes Cluster
â”‚
â”œâ”€â”€ ğŸ§  Control Plane (Master Node)	#The Control Plane continuously watches whatâ€™s actually running in the cluster (via kubelets on each node) and compares it to what you want to run (stored in etcd).
										If something doesnâ€™t match â€” a controller takes action to fix it automatically.
â”‚   â”œâ”€â”€ kube-apiserver    # Handles all API requests
â”‚   â”œâ”€â”€ etcd (key-value store) #Stores cluster state
â”‚   â”œâ”€â”€ kube-scheduler		#Decides which node runs each pod
â”‚   â””â”€â”€ kube-controller-manager	#Runs controllers to maintain desired state
â”‚
â””â”€â”€ ğŸ§± Worker Nodes (1..n)
    â”‚
    â”œâ”€â”€ kubelet (Node Agent)
    â”œâ”€â”€ kube-proxy (Networking)
    â”‚
    â””â”€â”€ ğŸ§© Pods (1..n per Node)
        â”‚
        â”œâ”€â”€ ğŸ³ Containers (your apps)
        â”‚   â”œâ”€â”€ e.g., Spring Boot App
        â”‚   â””â”€â”€ e.g., Database Sidecar
        â”‚
        â””â”€â”€ Shared resources (IP, storage, namespace)
		
Cluster
Controller
Nodes
Pods
Containers

ğŸ§© Flow Example

You create a Deployment â†’ API Server stores it.

Scheduler (on Control Plane) picks the best worker node.

API Server notifies that node.

Kubelet (on that node) receives the Pod spec.

Kubelet pulls the Docker image and starts the container.

Kube-proxy ensures the Pod is reachable through network rules.



What is etcd Exactly?

Itâ€™s a distributed key-value database.

It stores all cluster data, including:

Pods, Deployments, Services

ConfigMaps, Secrets

Node status, events, etc.

ğŸ§  Think of it as:

â€œThe brainâ€™s memoryâ€ of Kubernetes â€”
if itâ€™s not in etcd, Kubernetes forgets it.


How It Works in the Cluster
Example Flow:

You run:

kubectl apply -f deployment.yaml


The kube-apiserver receives that request.

It stores your Deployment definition inside etcd.

The controller-manager and scheduler read from etcd to decide what to do.

They make sure your desired state (stored in etcd) matches the actual state (on nodes).

Understanding Where etcd Data Lives

In a Minikube or local Kubernetes setup, the etcd database is running as a pod inside the control plane (master node).
That means itâ€™s not a directory on your Windows filesystem â€” itâ€™s inside a container running within Minikube.

ğŸ§© Step 1: Check if etcd is Running

Run this command:

kubectl get pods -n kube-system


Youâ€™ll see something like:

NAME                                    READY   STATUS    RESTARTS   AGE
etcd-minikube                           1/1     Running   0          2m
kube-apiserver-minikube                 1/1     Running   0          2m
kube-controller-manager-minikube        1/1     Running   0          2m
kube-scheduler-minikube                 1/1     Running   0          2m
...


âœ… Here, etcd-minikube is your etcd Pod.

ğŸ§© Step 2: Access the etcd Pod

Run this:

kubectl exec -it -n kube-system etcd-minikube -- sh


This opens a shell inside the etcd container.

ğŸ§© Step 3: Locate the etcd Data Directory

Once youâ€™re inside, check the data directory:

ls /var/lib/etcd


Youâ€™ll see something like:

member/
snap/


Thatâ€™s where etcd stores:

member/ â†’ actual database files (WAL and snapshots)

snap/ â†’ snapshot backups of the key-value store

ğŸ§© Step 4: (Optional) Inspect Keys in etcd

To see whatâ€™s inside etcd, you can run:

ETCDCTL_API=3 etcdctl get / --prefix --keys-only \
--cacert=/var/lib/minikube/certs/etcd/ca.crt \
--cert=/var/lib/minikube/certs/etcd/server.crt \
--key=/var/lib/minikube/certs/etcd/server.key


That lists all keys (resource states) stored in etcd â€” basically the entire Kubernetes cluster state (Pods, Deployments, etc.).

ğŸ§© Step 5: Exit the Pod

When done:

exit

ğŸ§­ Kubernetes Resource Hierarchy Diagram
ğŸŒ Cluster
â”‚
â”œâ”€â”€ ğŸ“¦ Namespaces (logical isolation)
â”‚   â”‚
â”‚   â”œâ”€â”€ âš™ï¸ Workloads
â”‚   â”‚   â”œâ”€â”€ Deployment
â”‚   â”‚   â”‚   â””â”€â”€ ReplicaSet
â”‚   â”‚   â”‚       â””â”€â”€ Pod
â”‚   â”‚   â”‚           â””â”€â”€ Container(s)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ StatefulSet
â”‚   â”‚   â”‚   â””â”€â”€ Pod
â”‚   â”‚   â”‚       â””â”€â”€ Container(s)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ DaemonSet
â”‚   â”‚   â”‚   â””â”€â”€ Pod (1 per Node)
â”‚   â”‚   â”‚       â””â”€â”€ Container(s)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ Job
â”‚   â”‚   â”‚   â””â”€â”€ Pod (runs once)
â”‚   â”‚   â””â”€â”€ CronJob
â”‚   â”‚       â””â”€â”€ Job (runs on schedule)
â”‚   â”‚           â””â”€â”€ Pod
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸŒ Networking
â”‚   â”‚   â”œâ”€â”€ Service
â”‚   â”‚   â”‚   â”œâ”€â”€ ClusterIP
â”‚   â”‚   â”‚   â”œâ”€â”€ NodePort
â”‚   â”‚   â”‚   â””â”€â”€ LoadBalancer
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ Ingress (routes external HTTP/S)
â”‚   â”‚   â”œâ”€â”€ NetworkPolicy (controls traffic)
â”‚   â”‚   â””â”€â”€ Endpoints / EndpointSlice
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ” Config & Secrets
â”‚   â”‚   â”œâ”€â”€ ConfigMap
â”‚   â”‚   â””â”€â”€ Secret
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ’¾ Storage
â”‚   â”‚   â”œâ”€â”€ PersistentVolumeClaim (PVC)
â”‚   â”‚   â”‚   â””â”€â”€ PersistentVolume (PV)
â”‚   â”‚   â””â”€â”€ StorageClass
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“Š Autoscaling
â”‚   â”‚   â”œâ”€â”€ HorizontalPodAutoscaler
â”‚   â”‚   â””â”€â”€ PodDisruptionBudget
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ‘¤ Access Control
â”‚   â”‚   â”œâ”€â”€ Role / RoleBinding (namespace level)
â”‚   â”‚   â”œâ”€â”€ ClusterRole / ClusterRoleBinding (cluster level)
â”‚   â”‚   â””â”€â”€ ServiceAccount (for Pod auth)
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ§© Custom Resources (CRDs)
â”‚       â”œâ”€â”€ ServiceMonitor (Prometheus)
â”‚       â”œâ”€â”€ Application (ArgoCD)
â”‚       â””â”€â”€ Many othersâ€¦
â”‚
â””â”€â”€ ğŸ§  Control Plane Components (Master)
    â”œâ”€â”€ kube-apiserver (API gateway)
    â”œâ”€â”€ etcd (cluster database)
    â”œâ”€â”€ kube-scheduler (assigns Pods to Nodes)
    â”œâ”€â”€ kube-controller-manager (manages controllers)
    â””â”€â”€ cloud-controller-manager (for cloud integration)